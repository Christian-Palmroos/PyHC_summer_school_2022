{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nPrfD4g5W6Dh"
   },
   "source": [
    "# Class Notebooks\n",
    "\n",
    "* [HAPI_00.ipynb](HAPI_00.ipynb) - Introduction\n",
    "* [HAPI_01.ipynb](HAPI_01.ipynb) - Basics\n",
    "* [HAPI_02.ipynb](HAPI_02.ipynb) - Data structures\n",
    "* [HAPI_03.ipynb](HAPI_03.ipynb) - Plotting\n",
    "* **[HAPI_04.ipynb](HAPI_04.ipynb) - Problems (this Notebook)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "# Instructions\n",
    "\n",
    "Use the rest of the class time to work on these problems. Each problem is expected to take at least one hour, so start with a problem that interests you.\n",
    "\n",
    "You are welcome to work on problems not given here. However, priority for questions will be given to students working on these problems.\n",
    "\n",
    "For in-person students, we encourage you to work with one or more neighbors on a problem.\n",
    "\n",
    "Several HAPI experts are available for questions on chat on Slack in the #hapi channel, and three of us will be on-site for in-person questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with Metadata I."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "## Basic\n",
    "\n",
    "\n",
    "Starting with\n",
    "\n",
    "```python\n",
    "import pickle as pickle\n",
    "with open('hapicache/availability.pkl', 'rb') as f:\n",
    "    datasets = pickle.load(f)\n",
    "\n",
    "print(datasets[0:3])\n",
    "# [{'id': 'ace', 'title': 'ACE', 'startDate': '1997-08-25T17:48:00.000Z', 'stopDate': '2022-07-04T23:48:00.000Z'}, {'id': 'active', 'title': 'Active', 'startDate': '1989-09-29T00:00:00.000Z', 'stopDate': '1991-10-04T08:00:00.000Z'}, {'id': 'aec', 'title': 'AE-C', 'startDate': '1973-12-17T08:01:00.000Z', 'stopDate': '1978-12-10T00:00:00.000Z'}]\n",
    "```\n",
    "\n",
    "use the information in `datasets` to create a table and plot as described in the following subsections. You should be able to do this without requesting additional information from a server.\n",
    "\n",
    "(The information in `datasets` was creating using `hapi()` [metadata calls](HAPI_02.ipynb#Metadata) to the SSCWeb HAPI server.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table\n",
    "\n",
    "Create a table showing the time interval of availability of ephemeris data from the SSCWeb HAPI server. The table should have the form\n",
    "\n",
    "    ace              1997-08-25T17:48:00.000Z  2022-07-04T23:48:00.000Z\n",
    "    active           1989-09-29T00:00:00.000Z  1991-10-04T08:00:00.000Z\n",
    "    aec              1973-12-17T08:01:00.000Z  1978-12-10T00:00:00.000Z\n",
    "    ... (243 more lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pickle\n",
    "with open('hapicache/availability.pkl', 'rb') as f:\n",
    "    datasets = pickle.load(f)\n",
    "print(datasets[0:3])\n",
    "\n",
    "# Enter your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot\n",
    "\n",
    "Create a plot showing the time interval of availability of ephemeris data from the SSCWeb HAPI server. The plot should look similar to the following."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](imgs/availability-1.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "### Solution\n",
    "\n",
    "A link to the solutions will be posted in the Slack #hapi channel at the end of the class period.\n",
    "\n",
    "## Advanced\n",
    "\n",
    "Write a program that creates the information in the dictionary `datasets` by querying the SSCWeb HAPI server. That is, write a program that creates the content that is stored in `availability.pkl`. (Metadata queries were covered in [HAPI_02.ipynb#Metadata](HAPI_02.ipynb#Metadata).)\n",
    "\n",
    "### Solution\n",
    "\n",
    "A link to the solutions will be posted in the Slack #hapi channel at the end of the class period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'datasets' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[38;5;28mprint\u001b[39m(datasets[i][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m datasets[i][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstartDate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m datasets[i][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstopDate\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Using enumerate and padding\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, dataset \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[43mdatasets\u001b[49m):\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;66;03m# Pad ids. Assumes max id length is 14 chars.\u001b[39;00m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28mid\u001b[39m \u001b[38;5;241m=\u001b[39m dataset[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     10\u001b[0m     idp \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{0:15s}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mid\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'datasets' is not defined"
     ]
    }
   ],
   "source": [
    "# Regular for loop\n",
    "if False:\n",
    "    for i in range(len(datasets)):\n",
    "        print(datasets[i]['id'] + ' ' + datasets[i]['startDate'] + ' ' + datasets[i]['stopDate'])\n",
    "\n",
    "# Using enumerate and padding\n",
    "for idx, dataset in enumerate(datasets):\n",
    "    # Pad ids. Assumes max id length is 14 chars.\n",
    "    id = dataset[\"id\"]\n",
    "    idp = '{0:15s}'.format(id)\n",
    "    line = f'{idp}  {dataset[\"startDate\"]}  {dataset[\"stopDate\"]}'\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "# Working with Metadata II.\n",
    "\n",
    "Starting with\n",
    "\n",
    "```python\n",
    "import pickle as pickle\n",
    "with open('hapicache/availability.pkl', 'rb') as f:\n",
    "    datasets = pickle.load(f)\n",
    "\n",
    "start = \"2003-10-31T23:00:00Z\"\n",
    "stop = \"2003-10-31T23:59:00Z\"\n",
    "```\n",
    "\n",
    "create a table that indicates the [spacecraft region](https://sscweb.gsfc.nasa.gov/users_guide/ssc_reg_doc.shtml) on `2003-10-31T23:00:00Z` for `ace`, `akebono`, `apex`, and `aqua` from SSCWeb. Your table should have columns of `Spacecraft ID`, `Region`, and `Time`, corresponding to the first time value on or after `start` as shown below.\n",
    "\n",
    "(Please do not attempt to create a table for all spacecraft - the SSCWeb HAPI server was not designed to handle a class of 300+ and so possibly 10-50 simultaneous requests.)\n",
    "\n",
    "```\n",
    "--------------------------------------------------------------------------------\n",
    "S/C ID           Region        Time\n",
    "\n",
    "ace              Intpl_Med\t 2003-304T23:00:00Z\n",
    "akebono          D_Psphere\t 2003-304T23:00:00Z\n",
    "apex             D_Msphere\t 2003-304T23:00:00Z\n",
    "aqua             N_Psphere\t 2003-304T23:00:00Z\n",
    "--------------------------------------------------------------------------------\n",
    "```\n",
    "\n",
    "## Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution\n",
    "ids = []\n",
    "starts = []\n",
    "stops = []\n",
    "n_max = len(datasets)\n",
    "#n_max = 50 # Plot only first n_max datasets\n",
    "\n",
    "# Solution to Working with Metadata I - Basic - 1.\n",
    "\n",
    "server = 'https://hapi-server.org/servers/SSCWeb/hapi'\n",
    "\n",
    "# Create table\n",
    "n = 0\n",
    "datasets.reverse()\n",
    "table = []\n",
    "for idx, dataset in enumerate(datasets):\n",
    "    ids.append(id)\n",
    "    starts.append(hapitime2datetime(datasets[idx][\"startDate\"])[0])\n",
    "    stops.append(hapitime2datetime(datasets[idx][\"stopDate\"])[0])\n",
    "    n = n + 1\n",
    "    if n > n_max:\n",
    "        break\n",
    "\n",
    "# Plot\n",
    "import matplotlib.pyplot as plt\n",
    "from hapiplot.plot.datetick import datetick\n",
    "\n",
    "def newfig():\n",
    "    fig, ax = plt.subplots()\n",
    "    fig.set_figheight(10)\n",
    "    fig.set_figwidth(8)\n",
    "    return ax\n",
    "\n",
    "def figconfig(ax):\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['left'].set_visible(False)\n",
    "    ax.grid(axis='x', which='minor', alpha=0.5, linestyle=':')\n",
    "    ax.grid(axis='x', which='major', color='k', alpha=0.5)\n",
    "    ax.set_yticks(ticks=[])\n",
    "    ax.set_title(f'{server}')\n",
    "    datetick('x')\n",
    "\n",
    "idx = []\n",
    "ax = newfig()\n",
    "fn = 1\n",
    "for n in range(len(ids)):\n",
    "    line, = ax.plot([starts[n], stops[n]], [n, n], linewidth=5)\n",
    "    lc = line.get_color()\n",
    "    idx.append(n)\n",
    "    ax.text(stops[n], n, ' ' + ids[n], color=lc, verticalalignment='center')\n",
    "    if (n + 1) % 50 == 0:\n",
    "        figconfig(ax)\n",
    "        plt.tight_layout()\n",
    "        fname = f\"./availability-{fn}.svg\"\n",
    "        plt.savefig(fname, bbox_inches='tight')\n",
    "        fn = fn + 1\n",
    "        ax = newfig()\n",
    "\n",
    "# Finish last plot, if needed\n",
    "if (n + 1) % 50 != 0:\n",
    "    figconfig(ax)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"./availability-{fn}.svg\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "# Working with Data\n",
    "\n",
    "Many datasets from CDAWeb contain ephemeris (position) data for the associated satellite.\n",
    "\n",
    "Use https://hapi-server.org/servers/ or https://heliophysicsdata.gsfc.nasa.gov/ to\n",
    "\n",
    "1. find a CDAWeb dataset that contains the ephemeris of a satellite, and\n",
    "2. find a SSCWeb dataset that contians the ephemeris of the same satellite.\n",
    "\n",
    "Then\n",
    "\n",
    "3. write a program to download the data, and  \n",
    "4. create a plot that compares the data.\n",
    "\n",
    "## Solution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hapiclient import hapi, hapitime2datetime\n",
    "\n",
    "server     = 'https://cdaweb.gsfc.nasa.gov/hapi'\n",
    "dataset    = 'AC_H0_MFI'\n",
    "parameters = 'SC_pos_GSE'\n",
    "start      = '1997-09-03T00:00:00Z'\n",
    "stop       = '1997-09-03T00:59:00.000Z'\n",
    "\n",
    "data_cdaweb, meta_cdaweb = hapi(server, dataset, parameters, start, stop)\n",
    "\n",
    "xyz_gse_cdaweb = list(data_cdaweb[0][1]/6371.)\n",
    "\n",
    "server     = 'http://hapi-server.org/servers/SSCWeb/hapi'\n",
    "dataset    = 'ace'\n",
    "parameters = 'X_GSE,Y_GSE,Z_GSE'\n",
    "\n",
    "data_sscweb, meta_sscweb = hapi(server, dataset, parameters, start, stop)\n",
    "\n",
    "xyz_gse_sscweb = [data_sscweb['X_GSE'][1],data_sscweb['Y_GSE'][1],data_sscweb['Z_GSE'][1]]\n",
    "\n",
    "time_cdaweb = data_cdaweb['Time'][0].decode()\n",
    "\n",
    "# Convert from YYYY-DOY to YYYY-MM-DD date format\n",
    "time_sscweb = hapitime2datetime([data_sscweb['Time'][0]])[0].strftime('%Y-%m-%dT%H:%M:%S.%fZ')\n",
    "\n",
    "# Time stamps are not idential. For a better comparison, use interpolation\n",
    "# or find time values that exactly match between SSCWeb and CDAWeb data.\n",
    "print('        {0:13s}{1:13s}{2:13s}'.format('X_GSE [R_E]', 'Y_GSE [R_E]', 'Z_GSE [R_E]'))\n",
    "print('SSCWeb: {0:<13.8f}{1:<13.8f}{2:<13.8f}\\t on {3:s}'.format(*xyz_gse_cdaweb, time_sscweb))\n",
    "print('CDAWeb: {0:<13.8f}{1:<13.8f}{2:<13.8f}\\t on {3:s}'.format(*xyz_gse_sscweb, time_cdaweb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "# Interpolating Time\n",
    "\n",
    "For analysis, it is often useful to place two datasets that have different timestamps on the same time grid. \n",
    "\n",
    "There are many ways to do this, for example,\n",
    "\n",
    "* Convert the timestamps in the NumPy `ndarray` returned by `hapi()` into integers, create a 1-D array of time integers to interpolate on to, and then either write your own interpolation function (not recommended) or use an interpolation function in [NumPy](https://numpy.org/doc/stable/reference/generated/numpy.interp.html) or [SciPy](https://docs.scipy.org/doc/scipy/reference/interpolate.html). An example of converting HAPI timestamps to `datetime` objects was given in [HAPI_02.ipynb#Time-Representation](HAPI_02.ipynb#Time-Representation); one can use [`datetime` methods](https://docs.python.org/3/library/datetime.html) to convert `datetime` objects into integers.\n",
    "\n",
    "\n",
    "* Place data in a Pandas `DataFrame` and use its interpolation methods (an example of placing data into a Pandas `DataFrame` was given in [HAPI_02.ipynb#Convert-to-Pandas-DataFrame](HAPI_02.ipynb#Convert-to-Pandas-DataFrame)).\n",
    "\n",
    "\n",
    "* In the [SpacePy](https://github.com/heliophysicsPy/summer-school/blob/main/spacepy-tutorial/SpacePy%20-%20MMS%20Ephemeris.md) tutorial (search on `tb.inter`) on Day 2, you used the [`interpol`](https://spacepy.github.io/autosummary/spacepy.toolbox.interpol.html#spacepy.toolbox.interpol) function in [`spacepy.toolbox`](https://spacepy.github.io/toolbox.html) to perform interpolation.\n",
    "\n",
    "Starting with the following program that reads datasets from two different data servers, use any library (or your own code) to\n",
    "\n",
    "1. write a program that interpolates `data2` on to the time grid of `data0` and\n",
    "\n",
    "2. create a table or plot that allows one to visually compare the interpolated values with the given values.\n",
    "\n",
    "Optionally,\n",
    "\n",
    "3. Write a program that averages `data0` into 1-hour time bins and compares the result with the contents of `data2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hapiclient import hapi, hapitime2datetime\n",
    "\n",
    "server     = 'https://cdaweb.gsfc.nasa.gov/hapi'\n",
    "dataset    = 'AC_H0_SWE'\n",
    "parameters = 'Np'\n",
    "start      = '1998-02-04'\n",
    "stop       = '1998-02-06'\n",
    "\n",
    "data0, meta0 = hapi(server, dataset, parameters, start, stop)\n",
    "print('data0 = ')\n",
    "print(data0)\n",
    "\n",
    "server     = 'https://cdaweb.gsfc.nasa.gov/hapi'\n",
    "dataset    = 'AC_H2_SWE'\n",
    "parameters = 'Np'\n",
    "start      = '1998-02-04'\n",
    "stop       = '1998-02-06'\n",
    "\n",
    "data2, meta2 = hapi(server, dataset, parameters, start, stop)\n",
    "print('\\ndata2 = ')\n",
    "print(data2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "# Coordinate Transform\n",
    "\n",
    "Starting with the following program,\n",
    "\n",
    "1. Print out the `GSE` and `GSM` values reported by SSCWeb.\n",
    "2. Use SpacePy to convert the `GSE` values to `GSM`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacepy.coordinates as sc\n",
    "from spacepy.time import Ticktock\n",
    "\n",
    "from hapiclient import hapi, hapitime2datetime\n",
    "\n",
    "server     = 'https://hapi-server.org/servers/SSCWeb/hapi'\n",
    "dataset    = 'swarma'\n",
    "parameters = 'X_GSE,Y_GSE,Z_GSE,X_GSM,Y_GSM,Z_GSM'\n",
    "start      = '2013-11-26T00:00:00Z'\n",
    "stop       = '2013-11-26T00:01:00Z'\n",
    "\n",
    "opts       = {'logging': True, 'usecache': True, 'cachedir': './hapicache'}\n",
    "\n",
    "data, meta = hapi(server, dataset, parameters, start, stop)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import logging\n",
    "\n",
    "from hapiclient import hapi\n",
    "from hapiclient import hapitime2datetime\n",
    "\n",
    "import pickle as pickle\n",
    "with open('hapicache/availability.pkl', 'rb') as f:\n",
    "    datasets = pickle.load(f)\n",
    "\n",
    "start = \"2003-10-31T23:00:00Z\"\n",
    "stop = \"2003-10-31T23:59:00Z\"\n",
    "\n",
    "short_run = True # If True, only get data for first three s/c\n",
    "\n",
    "server = 'https://hapi-server.org/servers/SSCWeb/hapi'\n",
    "start = \"2003-10-31T23:00:00Z\"\n",
    "stop = \"2003-10-31T23:59:00Z\"\n",
    "\n",
    "# Create table\n",
    "start_wanted = hapitime2datetime(start)\n",
    "stop_wanted  = hapitime2datetime(stop)\n",
    "\n",
    "n = 0\n",
    "for idx, dataset in enumerate(datasets):\n",
    "    # Pad ids\n",
    "    id = \"{:15s}\".format(datasets[idx][\"id\"])\n",
    "    start_available = hapitime2datetime(datasets[idx][\"startDate\"])[0]\n",
    "    stop_available = hapitime2datetime(datasets[idx][\"stopDate\"])[0]\n",
    "\n",
    "    if start_available <= start_wanted and stop_available >= stop_wanted:\n",
    "        n = n+1\n",
    "\n",
    "        logging.info(f'Getting data for {datasets[idx][\"id\"]} from {datasets[idx][\"startDate\"]} to {datasets[idx][\"stopDate\"]}')\n",
    "        data, meta = hapi(server, datasets[idx][\"id\"], 'Spacecraft_Region', start, stop, logging=False)\n",
    "\n",
    "        if len(data['Spacecraft_Region']) > 0:\n",
    "            datasets[idx][\"Spacecraft_Region\"] = data['Spacecraft_Region'][0]\n",
    "            datasets[idx][\"First_Value\"] = data['Time'][0].decode('utf-8')\n",
    "        else:\n",
    "            datasets[idx][\"Spacecraft_Region\"] = None\n",
    "\n",
    "    if short_run and n > 3:\n",
    "        break\n",
    "\n",
    "\n",
    "if short_run:\n",
    "    print(f'\\nAvailability of first 4 S/C from {start} to {stop}')\n",
    "else:\n",
    "    print(f'\\n{n} S/C have ephemeris data from {start} to {stop}')\n",
    "\n",
    "print(80*\"-\")\n",
    "print(\"S/C ID           Region      Time\")\n",
    "print(\"\")\n",
    "n = 0\n",
    "table = []\n",
    "for idx, dataset in enumerate(datasets):\n",
    "    id = \"{:15s}\".format(datasets[idx][\"id\"])\n",
    "    if \"Spacecraft_Region\" in datasets[idx]:\n",
    "        n = n + 1\n",
    "        if datasets[idx][\"Spacecraft_Region\"] is not None:\n",
    "            line = f'{id}  {datasets[idx][\"Spacecraft_Region\"]}\\t {datasets[idx][\"First_Value\"]}'\n",
    "        else:\n",
    "            line = f'{id}  No values available'\n",
    "        print(line)\n",
    "        table.append(line)\n",
    "\n",
    "    if short_run and n > 3:\n",
    "        break\n",
    "print(80*\"-\")\n",
    "\n",
    "sys.stdout.flush()\n",
    "\n",
    "from datetime import datetime\n",
    "logging.info(\"Writing region.txt\")\n",
    "with open('region.txt', 'w', encoding = 'utf-8') as f:\n",
    "    f.write(\"Table created on \" + datetime.now().isoformat() + \"\\n\\n\")\n",
    "    f.write(\"\\n\".join(table))\n",
    "logging.info(\"Wrote   region.txt\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "# SunPy Data Fusion\n",
    "\n",
    "In the last part of the [SunPy Tutorial](https://github.com/heliophysicsPy/summer-school/blob/main/sunpy-tutorial/05-multi-observer-application.ipynb), you plotted solar images on 2021-04-24. \n",
    "\n",
    "Solar wind plasma typically ~4 days to propagate from the solar surface to Earth. \n",
    "\n",
    "Find and plot data from at least one spacecraft from `2021-04-24` to `2021-04-30`. Be prepared to answer questions about your interpretation of any features in the time series."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "hapi_demo.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "git": {
   "suppress_output": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
